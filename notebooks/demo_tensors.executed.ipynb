{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5d5e993",
   "metadata": {},
   "source": [
    "# Demo Tensors Dataset (HDF5)\n",
    "\n",
    "This notebook demonstrates the generation and usage of the Demo Tensors dataset, which includes a diverse range of tensor dimensions (0D to 5D).\n",
    "\n",
    "The dataset is generated by `scripts/generate_tensors.py` and results in an HDF5 file (`.h5`) located at `data/synthetic/demo_tensors/demo_tensors.h5` (relative to the repository root).\n",
    "\n",
    "**Note**: To run this notebook, you will need the `h5py` library. If you haven't installed it yet, you can do so by running:\n",
    "```bash\n",
    "pip install h5py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown-generate",
   "metadata": {},
   "source": [
    "## 1. Generate the Dataset\n",
    "\n",
    "The following cell executes the script `scripts/generate_tensors.py`.\n",
    "This script now generates several tensors and saves them into `demo_tensors.h5`: \n",
    "`tensor_a`, `tensor_b`, `scalar_data`, `vector_data`, `image_grayscale_data`, `image_rgb_data`, `video_frames_data`, and `simulation_data`.\n",
    "\n",
    "Since this notebook is in the `notebooks/` directory, we use `../` to correctly path to the script and the output directory.\n",
    "This command will create (or overwrite) `../data/synthetic/demo_tensors/demo_tensors.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62464c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T06:02:05.024139Z",
     "iopub.status.busy": "2025-06-08T06:02:05.023813Z",
     "iopub.status.idle": "2025-06-08T06:02:05.701733Z",
     "shell.execute_reply": "2025-06-08T06:02:05.700321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated demo_tensors.h5 in /app/data/synthetic/demo_tensors\r\n"
     ]
    }
   ],
   "source": [
    "!python ../scripts/generate_tensors.py ../data/synthetic/demo_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "markdown-load",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect the Data from HDF5 File\n",
    "\n",
    "Now, we'll load the generated `demo_tensors.h5` file using the `h5py` library.\n",
    "We will then list all datasets (tensors) stored within the file and inspect each one, showing its shape, data type (dtype), and for the scalar, its value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4b990e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T06:02:05.706271Z",
     "iopub.status.busy": "2025-06-08T06:02:05.705927Z",
     "iopub.status.idle": "2025-06-08T06:02:05.972185Z",
     "shell.execute_reply": "2025-06-08T06:02:05.970904Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load data from: ../data/synthetic/demo_tensors/demo_tensors.h5\n",
      "\n",
      "Available datasets in HDF5: ['image_grayscale_data', 'image_rgb_data', 'scalar_data', 'simulation_data', 'tensor_a', 'tensor_b', 'vector_data', 'video_frames_data']\n",
      "\n",
      "Dataset: 'tensor_a' (Original general 2D tensor)\n",
      "  Shape: (100, 3)\n",
      "  dtype: float64\n",
      "---\n",
      "Dataset: 'tensor_b' (Original general 3D tensor)\n",
      "  Shape: (50, 10, 3)\n",
      "  dtype: float64\n",
      "---\n",
      "Dataset: 'scalar_data' (0D tensor (scalar))\n",
      "  Shape: ()\n",
      "  dtype: float64\n",
      "  Value: 42.0\n",
      "---\n",
      "Dataset: 'vector_data' (1D tensor (vector))\n",
      "  Shape: (150,)\n",
      "  dtype: float64\n",
      "---\n",
      "Dataset: 'image_grayscale_data' (2D tensor (grayscale image))\n",
      "  Shape: (32, 32)\n",
      "  dtype: float64\n",
      "---\n",
      "Dataset: 'image_rgb_data' (3D tensor (RGB image))\n",
      "  Shape: (16, 16, 3)\n",
      "  dtype: float64\n",
      "---\n",
      "Dataset: 'video_frames_data' (4D tensor (sequence of grayscale frames))\n",
      "  Shape: (10, 8, 8, 1)\n",
      "  dtype: float64\n",
      "---\n",
      "Dataset: 'simulation_data' (5D tensor (higher-dimensional data))\n",
      "  Shape: (5, 6, 6, 3, 2)\n",
      "  dtype: float64\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np # Still useful for verifying dtypes or further operations\n",
    "\n",
    "# Define the path to the data file (relative to this notebook)\n",
    "data_path = '../data/synthetic/demo_tensors/demo_tensors.h5'\n",
    "\n",
    "print(f\"Attempting to load data from: {data_path}\\n\")\n",
    "\n",
    "with h5py.File(data_path, 'r') as hf:\n",
    "    print(f\"Available datasets in HDF5: {sorted(list(hf.keys()))}\\n\")\n",
    "\n",
    "    # Define the tensors we expect to find (and their descriptions for printing)\n",
    "    tensor_info = {\n",
    "        \"tensor_a\": \"Original general 2D tensor\",\n",
    "        \"tensor_b\": \"Original general 3D tensor\",\n",
    "        \"scalar_data\": \"0D tensor (scalar)\",\n",
    "        \"vector_data\": \"1D tensor (vector)\",\n",
    "        \"image_grayscale_data\": \"2D tensor (grayscale image)\",\n",
    "        \"image_rgb_data\": \"3D tensor (RGB image)\",\n",
    "        \"video_frames_data\": \"4D tensor (sequence of grayscale frames)\",\n",
    "        \"simulation_data\": \"5D tensor (higher-dimensional data)\"\n",
    "    }\n",
    "\n",
    "    for name, description in tensor_info.items():\n",
    "        if name in hf:\n",
    "            dataset = hf[name] # Access the HDF5 dataset object\n",
    "            print(f\"Dataset: '{name}' ({description})\")\n",
    "            print(f\"  Shape: {dataset.shape}\")\n",
    "            print(f\"  dtype: {dataset.dtype}\")\n",
    "            \n",
    "            # Load data into memory as NumPy array to work with it\n",
    "            if name == 'scalar_data':\n",
    "                value = dataset[()] # Use [()] for scalars\n",
    "                print(f\"  Value: {value}\")\n",
    "            else:\n",
    "                # For other tensors, you might load them fully using [:]\n",
    "                # array_data = dataset[:] \n",
    "                # print(f\"  First element if loaded: {array_data.flatten()[0] if array_data.size > 0 else 'N/A'}\")\n",
    "                pass # Avoid loading large arrays fully in this overview\n",
    "            print(\"---\")\n",
    "        else:\n",
    "            print(f\"Dataset: '{name}' was not found in the file.\")\n",
    "            print(\"---\")\n",
    "\n",
    "# The file hf is automatically closed when exiting the 'with' block."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
